{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize with SciPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say hello to [SciPy](https://www.scipy.org/), a powerful library used for mathematics in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous exercise, we saw the importance of finding the minimum of a given function - for instance, `RMSE = f(intercept_coef, slope_coef)`, and the two main approaches possible: iterative approaches (such as gradient descent) and closed-formed (such as matrix inversion).\n",
    "\n",
    "Let's discover the [`scipy.optimize`](https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html) library to find the **local** minimium of a function in a few lines of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import optimize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D-function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose a given function f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return (x**2 - 20 * np.cos(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Plot it below between -10 and +10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Find the local minimum of f, from a starting point `x0`, using `scipy.optimize.minimize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Notice the minimum found in variable `x`, and the number of iterations it took to converge: `nit`. What can you conclude?  \n",
    "Try to change the `x0`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üëâ Explanations</summary>\n",
    "After <code>nit</code> iterations, the algorithm of the <code>minimize()</code> function gets stuck on a local minimum <code>x</code>, except if it starts from values of <code>x0</code> close enough to the global minimum (0). The value of the local minimum found is <code>fun</code>\n",
    "    \n",
    "In math, we say that this function is not [convex](https://en.wikipedia.org/wiki/Convex_function). If it were convex, any minimum would be the global minimum! In fact, machine-learning loves convexity, and such problems are very easy to solve with iterative processes such as gradient descent.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D-function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in previous exercise, finding the minimum of a function with more than one parameter becomes rapidly complex. Let's try out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(X):\n",
    "    return -(X[1] + 47) * np.sin(np.sqrt(abs(X[0]/2 + (X[1]  + 47)))) \\\n",
    "        -X[0] * np.sin(np.sqrt(abs(X[0] - (X[1]  + 47))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to visualize `g` in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a (50*50) meshgrid\n",
    "x = np.linspace(-150,150,100) # shape(100,1)\n",
    "y = np.linspace(-150,150,100) # shape(100,1)\n",
    "xx, yy = np.meshgrid(x,y) # x and y of shape(100,100)\n",
    "zz = np.array([xx, yy]) # (2, 100, 100)\n",
    "\n",
    "# Compute Z, a 2D-array containing g(x,y) for each (x,y) in the meshgrid\n",
    "Z = g(zz)\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(xx, yy, Z, cmap='terrain')\n",
    "ax.set_xlabel('x'); ax.set_ylabel('y'); ax.set_zlabel('g(x, y)'); ax.view_init(45, -45);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìInitialize a starting point `X0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìFind a `minimum` using `scipy.optimize.minimize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and store the minimum inside a `minimum` variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìDoes this look like the absolute minimum? Check it out below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this out\n",
    "\n",
    "x = np.linspace(-150,150,100) # shape(100,1)\n",
    "y = np.linspace(-150,150,100) # shape(100,1)\n",
    "xx, yy = np.meshgrid(x,y) # x and y of shape(100,100)\n",
    "zz = np.array([xx,yy]) # shape(2, 100, 100)\n",
    "\n",
    "plt.contourf(xx,yy,g(zz), 40)\n",
    "plt.colorbar()\n",
    "plt.scatter(minimum[0], minimum[1], c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably only found a **local** minimum to your objective function f, given a starting point $X0$.\n",
    "\n",
    "‚ùì Can you think of a procedure that would increase your chance of finding the **global** minima?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí°Hints</summary>\n",
    "\n",
    "üëâ One empirical idea is to loop over lots of random starting points $X0$, and store the minimum value found at each run. After each iteration, you increase your chance of finding the global minimum (if there is any)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('minimize2d',\n",
    "    X0_shape=X0.shape,\n",
    "    minimum_shape=minimum.shape\n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimize under constraint üî•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real world problems, we often want to minimize a function $h(\\textbf{x})$, **given a set of constraints on the values of $\\textbf{x}$ itself**.   \n",
    "\n",
    "See for instance, the famous [Knapsack problem](https://en.wikipedia.org/wiki/Knapsack_problem) üéí\n",
    "\n",
    "As often in Math, the hardest part is not to solve the equations but to convert your real-world problem into mathematical equations. But for the sake of this challenge, let's assume we came with the following problem statement:\n",
    "\n",
    "---\n",
    "Find $\\textbf{x}$ that minimizes $h(\\textbf{x}) = x_1 x_4 (x_1 + x_2 + x_3) + x_3$  \n",
    "\n",
    "Given the following constraints\n",
    "\n",
    "\n",
    "$[1]\\ \\ x_1^2 + x_2^2 + x_3^2 + x_4^2 = 40$  (*equality constraint*)\n",
    "\n",
    "$[2]\\ \\ x_1 x_2 x_3 x_4 \\leqslant 25$ (*inequality constraint*)\n",
    "\n",
    "$[3]\\ \\ 1 \\leqslant x_1, x_2, x_3, x_4 \\leqslant 5$ (*bounds*)\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Re-use the `minimize` method to find a local minimum using additional arguments as follows: \n",
    "\n",
    "`optimize.minimize(h, X0, constraints=cons, bounds=boundaries)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your objective function h(X) that you want to minimize, X being a 1D-array of lenght 4\n",
    "def h(X):\n",
    "    pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function constraint1(X) that returns 0 if and only if equation [1] is True\n",
    "# Otherwise it should return any other number\n",
    "def constraint1(X):\n",
    "    pass  # YOUR CODE HERE\n",
    "\n",
    "# Define a function constraint2(X) that returns a positive number if and only if equation [2] is True\n",
    "# Otherwise it should return a negative number \n",
    "def constraint2(X):\n",
    "    pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° Hint</summary>\n",
    "    The above functions do not require an if else statement if we convert our constraints to Math equations.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now define for you the \"constraint\" argument needed for the minimize function. Pay attention to the scipy syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "con1 = {\"type\": \"eq\", \"fun\": constraint1}\n",
    "con2 = {\"type\": \"ineq\", \"fun\": constraint2}\n",
    "constraints = [con1, con2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Let's deal with equation [3].\n",
    "We could write them in the form of 10 constraints functions, but it would be long  \n",
    "Instead, scipy allows us to create \"boundaries\" arguments for the variables we look for, in the following form:  \n",
    "`bounds` = tuple of tuple `((x1_min, x_1_max), (x2_min, x_2_max), ....)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, define any starting point X0 for the minimization algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Now, try to find the minimum of your objective function `f` under such constraints using `optimize.minimize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize under constraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the minimum in a `local_minimum` variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check constraints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('minimize_constraints',\n",
    "    bounds=bounds,\n",
    "    X0=X0,\n",
    "    Xmin=local_minimum\n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed, `scipy.optimize.minimize` only finds  the local minima **in the vicinity of X0**. To find the **global** minima, you basically have two options:\n",
    "\n",
    "1. Prove mathematically that your optimization problem is geometrically [convex](https://en.wikipedia.org/wiki/Convex_function). An optimization problem is convex in the following case: (i) its objective function `h` is a convex function, (ii) the inequality constraints are convex, and (iii) the equality constraints are affine. Read in this excellent math-based presentation from Berkeley if you want to dig further: [Convex Optimization for Machine Learning](https://people.eecs.berkeley.edu/~jordan/courses/294-fall09/lectures/optimization/slides.pdf)\n",
    "\n",
    "\n",
    "2. Loop over lots of starting points $X0$ and look for local minima nearby. Store the minimum value found at each run. After each iteration, you increase your chance of finding the global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2 is exactly what the following scipy libraries do under the hood: they _efficiently_ search the parameter space, while using `minimize` at each iteration. It works great when the number of parameters to search for (degree of freedom) is small ([`scipy.optimize.shgo`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.shgo.html#scipy.optimize.shgo) or [`scipy.optimize.dual_annealing`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.dual_annealing.html))\n",
    "\n",
    "However, they only return a \"global\" minima **within specified boundaries** for the parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìTry to use the two functions to find the global minima for our previous 2D-function $g(x,y)$, bounded between -150 and +150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a variable `bounds` with boundaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the global minimum `minimum_shgo` with the scipy.optimize.shgo method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this out\n",
    "\n",
    "x = np.linspace(-150,150,100) # shape(100,1)\n",
    "y = np.linspace(-150,150,100) # shape(100,1)\n",
    "xx, yy = np.meshgrid(x,y) # x and y of shape(100,100)\n",
    "zz = np.array([xx,yy]) # shape(2, 100, 100)\n",
    "\n",
    "plt.contourf(xx,yy,g(zz), 40)\n",
    "plt.colorbar()\n",
    "plt.scatter(minimum_shgo[0], minimum_shgo[1], c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the global minimum `minimum_dual` with the scipy.optimize.dual_annealing method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this out\n",
    "\n",
    "x = np.linspace(-150,150,100) # shape(100,1)\n",
    "y = np.linspace(-150,150,100) # shape(100,1)\n",
    "xx, yy = np.meshgrid(x,y) # x and y of shape(100,100)\n",
    "zz = np.array([xx,yy]) # shape(2, 100, 100)\n",
    "\n",
    "plt.contourf(xx,yy,g(zz), 40)\n",
    "plt.colorbar()\n",
    "plt.scatter(minimum_dual[0], minimum_dual[1], c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('global_optimization',\n",
    "    bounds=bounds,\n",
    "    Xmin_shgo=minimum_shgo,\n",
    "    Xmin_dual=minimum_dual\n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often have to fit a scatterplot with a straight line, but it can also happen to look like something else (polynomial, logarithmic etc...)\n",
    "\n",
    "Consider the dataset below: would you try to fit a linear regression curve to it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-3.        , -2.87755102, -2.75510204, -2.63265306, -2.51020408,\n",
    "       -2.3877551 , -2.26530612, -2.14285714, -2.02040816, -1.89795918,\n",
    "       -1.7755102 , -1.65306122, -1.53061224, -1.40816327, -1.28571429,\n",
    "       -1.16326531, -1.04081633, -0.91836735, -0.79591837, -0.67346939,\n",
    "       -0.55102041, -0.42857143, -0.30612245, -0.18367347, -0.06122449,\n",
    "        0.06122449,  0.18367347,  0.30612245,  0.42857143,  0.55102041,\n",
    "        0.67346939,  0.79591837,  0.91836735,  1.04081633,  1.16326531,\n",
    "        1.28571429,  1.40816327,  1.53061224,  1.65306122,  1.7755102 ,\n",
    "        1.89795918,  2.02040816,  2.14285714,  2.26530612,  2.3877551 ,\n",
    "        2.51020408,  2.63265306,  2.75510204,  2.87755102,  3.        ])\n",
    "y = np.array([31.66815357, 31.26229494, 30.3467807 , 28.2057809 , 25.47674964,\n",
    "       22.81398414, 19.93953021, 19.38250362, 20.02551935, 17.44468883,\n",
    "       17.80733403, 16.29808282, 14.85006259, 12.69760597, 13.04075803,\n",
    "       10.42420089,  7.91118094,  9.72737214,  9.05962483,  6.89984054,\n",
    "        8.15068899,  5.15772899,  7.65448235,  4.95987628,  4.4284636 ,\n",
    "        3.22183541,  3.05456124,  3.49253584,  2.23478284,  4.15163314,\n",
    "        3.68063488,  5.22556445,  2.47139029,  2.66785497,  3.72557952,\n",
    "        2.56255802,  4.61385762,  4.28234911,  4.91138639,  5.31724926,\n",
    "        6.52053679,  5.94175001,  7.5368359 ,  9.78905172,  9.5795072 ,\n",
    "       10.95610291, 11.73051576, 12.85008617, 12.2184079 , 16.52977769])\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A polynomial estimator of degree 2 seems more appropriate in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function f of degree two with parameters (a,b,c)\n",
    "def f(x,a,b,c):\n",
    "    pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to find the best params (a,b,c). We could again reuse the `optimize.minimize` method to minimize the mean square error between our estimator $f$ and our scatter plot...\n",
    "\n",
    "Fortunately, the handy method [`scipy.optimize.curve_fit`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html) does just that in one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it out\n",
    "optimize.curve_fit(f, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first array contains coefficients that have been computed to minimize square errors between $f$ and the dataset  .\n",
    "The second array contains the matrix of covariance.\n",
    "\n",
    "‚ùìPlot your quadratic estimator on top of the scatter plot to check that it fits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with any spreadsheet softwares, we often want to quickly fill the blanks in a series of datapoints. We'll use [`scipy.interpolate`](https://docs.scipy.org/doc/scipy/reference/interpolate.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's consider the following scatterplot\n",
    "x = np.linspace(0, 10, 10)\n",
    "y = np.array([ 0.        ,  0.8961922 ,  0.79522006, -0.19056796, -0.96431712,\n",
    "       -0.66510151,  0.37415123,  0.99709789,  0.51060568, -0.54402111])\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `interpolate.interp1d()` method to create a continuous function for any value $x$ in this range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_interpolated = interpolate.interp1d(x,y, kind='linear')\n",
    "f_interpolated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now call your interpolated function with any continuous values for $x$ in the initial range. Vizualize it with a new plot and a denser `linspace`for x. Feel free to try other `kind` of interpolations such as `quadratic` or `cubic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR PLOT HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}