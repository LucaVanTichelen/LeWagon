{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp81GSFN7uHY"
   },
   "source": [
    "# Transfer Learning\n",
    "\n",
    "**Exercise objetives**\n",
    "- Use a pretrained neural network : Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAkNOgtqF7S_"
   },
   "source": [
    "#### Transfer what?\n",
    "We have seen that the convolutions are mathematical operation that detect specific patterns in input images and use them to classify the image. One could imagine that these patterns are not 100% specific to the task but to the input images. \n",
    "\n",
    "üí° Therefore, **why not using convolutions that have been learnt on other task** with the expectation that it will also work in other scenario?  We _transfer_ a CNN from one task to another => _transfer learning_. This has two advantages:\n",
    "- taking less time to train\n",
    "- benefiting from complex architecture that have been trained for state-of-the-art challenges. \n",
    "\n",
    "‚ö†Ô∏è Although convolutions may not be specific, the last layer is by design specific to the problem it was trained on! Therefore, this last layer is usually removed, replace by a layer that is design to the task. As this new last layer has random weight, it has to be retrained. This is called _fine-tunning_. \n",
    "\n",
    "#### VGG16\n",
    "In this exercise, we will use the [VGG-16 Neural Network](https://neurohive.io/en/popular-networks/vgg16/), a well-known architecture that has been trained on ImageNet which is a very large database of images of different categories. In a nutshell, this architecture has already learnt kernels which are supposed to be good not only for the task it has been train on but maybe for other tasks. \n",
    "\n",
    "<center><img src=\"https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png\" width=400></center>\n",
    "\n",
    "The idea is that first layers are not specialized for the particular task it has been trained on ; only the last ones are. Therefore, we will \n",
    "- load the existing VGG16 network\n",
    "- remove the last fully connected layers\n",
    "- replace them by new connected layers (whose weights are randomly set)\n",
    "- and train these last layers on a specific classification task - here, separate types of flower. \n",
    "\n",
    "The underlying idea is that the first convolutional layers of VGG-16, that has already been trained, corresponds to filters that are able to extract meaning features from images. And you will only learn the last layers for your particular problem.\n",
    "\n",
    "<hr>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-S858KRF7TA"
   },
   "source": [
    "# 1. Data loading & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdS5hErJF7TB"
   },
   "source": [
    "You have two options to load the data on Google Colab.\n",
    "\n",
    "\n",
    "**Option 1: Loading the data directly**\n",
    "\n",
    "You can first get the data onto google Colab thanks to:\n",
    "\n",
    "`!wget https://wagon-public-datasets.s3.amazonaws.com/flowers-dataset.zip`,\n",
    "\n",
    "and then run \n",
    "\n",
    "`!unzip flowers-dataset.zip`\n",
    "\n",
    "This is a very easy option to load the data into your working directory.\n",
    "\n",
    "**Option 2: Adding the data to Google Drive.**\n",
    "\n",
    "You can first download the data  from `https://wagon-public-datasets.s3.amazonaws.com/flowers-dataset.zip`. Then you have to add them to your Google Drive in a folder called `Deep_learning_data` (for instance) and run the following code in the notebook.: \n",
    "\n",
    "```\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "```\n",
    "\n",
    "The previous code will ask you to go to a given webpage where you copy the link and past it in the Colab form that will appear. Do so to load the data on Google Colab.\n",
    "\n",
    "Why choosing this option over the first one? This can be of interest if you work in a project team, and update the data from time to time. By doing this, you can share the same data folder within a team, and be sure that everyone has the same at any time, even though someone changes it. The drawback is that Google Colab has now access to your Google Folder, which you might not be or not in favor of, depending on your sensibility.\n",
    "\n",
    "\n",
    "‚ùì **Question** ‚ùì Use one of the above method to load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "hKw_1TjOF7TC"
   },
   "outputs": [],
   "source": [
    "option_1 = True # Choose here\n",
    "\n",
    "if option_1:\n",
    "    !wget https://wagon-public-datasets.s3.amazonaws.com/flowers-dataset.zip\n",
    "    !unzip flowers-dataset.zip\n",
    "else:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onPwIzQzF7TE"
   },
   "source": [
    "‚ùì **Question** ‚ùì Use the following method to create \n",
    "`X_train, y_train, X_val, y_val, X_test, y_test, num_classes` depending on the `loading_method` you have used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "executionInfo": {
     "elapsed": 8945,
     "status": "ok",
     "timestamp": 1619617432025,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "XPJiWZVjF7TF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def load_flowers_data(loading_method):\n",
    "    if loading_method == 'colab':\n",
    "        data_path = '/content/drive/My Drive/Deep_learning_data/flowers'\n",
    "    elif loading_method == 'direct':\n",
    "        data_path = 'flowers/'\n",
    "    classes = {'daisy':0, 'dandelion':1, 'rose':2}\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for (cl, i) in classes.items():\n",
    "        images_path = [elt for elt in os.listdir(os.path.join(data_path, cl)) if elt.find('.jpg')>0]\n",
    "        for img in tqdm(images_path[:300]):\n",
    "            path = os.path.join(data_path, cl, img)\n",
    "            if os.path.exists(path):\n",
    "                image = Image.open(path)\n",
    "                image = image.resize((256, 256))\n",
    "                imgs.append(np.array(image))\n",
    "                labels.append(i)\n",
    "\n",
    "    X = np.array(imgs)\n",
    "    num_classes = len(set(labels))\n",
    "    y = to_categorical(labels, num_classes)\n",
    "\n",
    "    # Finally we shuffle:\n",
    "    p = np.random.permutation(len(X))\n",
    "    X, y = X[p], y[p]\n",
    "\n",
    "    first_split = int(len(imgs) /6.)\n",
    "    second_split = first_split + int(len(imgs) * 0.2)\n",
    "    X_test, X_val, X_train = X[:first_split], X[first_split:second_split], X[second_split:]\n",
    "    y_test, y_val, y_train = y[:first_split], y[first_split:second_split], y[second_split:]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4149,
     "status": "ok",
     "timestamp": 1619621571579,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "KlO39-AMF7TG",
    "outputId": "230e8818-404f-414f-c447-8c128dbd3a82"
   },
   "outputs": [],
   "source": [
    "# CALL load_flowers_data WITH YOUR PREFERRED METHOD HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pm2IsMmGF7TH"
   },
   "source": [
    "‚ùì Check image shape and plot few of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdMfP6dyF7TJ"
   },
   "source": [
    "# 2. Home made model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njYcWjw1F7TJ"
   },
   "source": [
    "First, let's check our performance on a home-made CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wneAeLYdF7TK"
   },
   "source": [
    "‚ùì **Questions** ‚ùì \n",
    "\n",
    "- Build, compile and fit a CNN model adapted to the challenge.\n",
    "- Compare performance with baseline \n",
    "- We recommand to use the following architecture\n",
    "\n",
    "---\n",
    "```python\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Notice this cool new layer that \"pipe\" your rescaling within the architecture\n",
    "model.add(Rescaling(1./255, input_shape=(256,256,3)))\n",
    "\n",
    "# Lets add 3 convolution layers, with relatively large kernel size as our pictures are quite big too\n",
    "model.add(layers.Conv2D(16, kernel_size=10, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "model.add(layers.Conv2D(32, kernel_size=8, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "model.add(layers.Conv2D(32, kernel_size=6, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sx8V9sny7cLP"
   },
   "source": [
    "# 3. Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nr6m5eKs9s54"
   },
   "source": [
    "## 3.1 Load VGG16 model\n",
    "\n",
    "\n",
    "‚ùì **Question** ‚ùì Write a first function `load_model()` that loads the pretrained VGG-16 model from `tensorflow.keras.applications.vgg16`. Especially, look at the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16) to load the model where:\n",
    "- the `weights` have been learnt on `imagenet`\n",
    "- the `input_shape` corresponds to the input shape of any of your images - you have to resize them in case they are not of the same size\n",
    "- the `include_top` argument is set to `False` in order not to load the fully-connected layers of the VGG-16 without the last layer which was specifically trained on `imagenet`\n",
    "\n",
    "‚ùó **Remark** ‚ùó Do not change the default value of the other arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "executionInfo": {
     "elapsed": 637,
     "status": "ok",
     "timestamp": 1619620808024,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "fQAVMEWLF7TN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "def load_model():\n",
    "    pass  # YOUR CODE HERE\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3psG3JGF7TO"
   },
   "source": [
    "‚ùì **Question** ‚ùì Look at the architecture of the model thanks to the summary method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 767,
     "status": "ok",
     "timestamp": 1619620819832,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "JtBpKLegF7TO",
    "outputId": "0a3745d6-cd2c-4dc3-fdab-5048b01b9053",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1IAwxRVF7TO"
   },
   "source": [
    "<img src=\"https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png\">\n",
    "\n",
    "Impressive, right? Two things to notice:\n",
    "- It ends with a convolution layer (namely a maxpooling layer that is the layer that follows a convolution). The flattening of the output and the fully connected layers are not here yet! We need to add them !\n",
    "- There are more than 14.000.000 parameters, which is a lot. We could fine-tune them, meaning update them as we will update the last layers weights, but it will take a lot of time. For that reason, we will inform the model that the layers until the flattening are non-trainable.\n",
    "\n",
    "‚ùì **Question** ‚ùì Write a first function that takes the previous model as input the set the first layers to be non-trainable, by applying `model.trainable = False`. Then check-out the summary of the model to see that now, the parameters are `non-trainable`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_nontrainable_layers(model):\n",
    "    # Set the first layers to be untrainable\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4yedT2VF7TP"
   },
   "source": [
    "‚ùì **Question** ‚ùì We will write a function that adds flattening and dense layers after the first convolutional layers. To do so, cannot directly use the classic `layers.Sequential()` instantiation.\n",
    "\n",
    "For that reason, we will see another one here. The idea is that we define each layer (or group of layers) separately. Then, we concatenate them. See this example : \n",
    "\n",
    "---\n",
    "```python\n",
    "base_model = load_model()\n",
    "base_model = set_nontrainable_layers(base_model)\n",
    "flattening_layer = layers.Flatten()\n",
    "dense_layer = layers.Dense(SOME_NUMBER_1, activation='relu')\n",
    "prediction_layer = layers.Dense(SOME_NUMBER_2, activation='APPROPRIATE_ACTIVATION')\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  flattening_layer,\n",
    "  dense_layer,\n",
    "  prediction_layer\n",
    "])\n",
    "\n",
    "```\n",
    "---\n",
    "The first line loads a group of layer which is the previous VGG-16 model. Then, we set this layers to be non-tranable. Then, we can instantiate as many layers as we want.\n",
    "\n",
    "Finally, we use the `Sequential` with the sequence of layers that will correspond to our overall neural network. \n",
    "\n",
    "Replicate the following steps by adding a flattening and two dense layers (the first with 500 neurons) to the previous VGG-16 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "executionInfo": {
     "elapsed": 334,
     "status": "ok",
     "timestamp": 1619620821513,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "OfgJDh_9F7TQ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def add_last_layers(model):\n",
    "    '''Take a pre-trained model, set its parameters as non-trainables, and add additional trainable layers on top'''\n",
    "    pass  # YOUR CODE HERE\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-24j0psF7TQ"
   },
   "source": [
    "‚ùì **Question** ‚ùì Now look at the layers and parameters of your model. Note that there is a distinction, at the end, between the trainable and non-trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1619620823208,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "0uqGuxsJF7TR",
    "outputId": "c0d4fffa-7a7f-402b-e97f-480edd2d3b3a",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxXlnPp5F7TR"
   },
   "source": [
    "‚ùì **Question** ‚ùì Write a function that build (and compile) your model - we advise Adam with `learning_rate=1e-4`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "executionInfo": {
     "elapsed": 818,
     "status": "ok",
     "timestamp": 1619620831671,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "kscw585CF7TS"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "def build_model():\n",
    "    pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbkwOw1eF7TS"
   },
   "source": [
    "## 3.2 Back to the data\n",
    "\n",
    "The VGG16 model was trained on images which were preprocessed in a specific way. This is the reason why we did not normalized them earlier.\n",
    "\n",
    "‚ùì **Question** ‚ùì Apply this processing to the original (non-normalized) images here using the method `preprocess_input` that you can import from `tensorflow.keras.applications.vgg16`. See [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg16/preprocess_input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "executionInfo": {
     "elapsed": 602,
     "status": "ok",
     "timestamp": 1619621142064,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "B--Gyb-23YDb"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "executionInfo": {
     "elapsed": 1259,
     "status": "ok",
     "timestamp": 1619621304912,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "uNeJZvtV3YDf",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wu2H0KZF-EoI"
   },
   "source": [
    "## 3.3 Fit the model\n",
    "\n",
    "‚ùì **Question** ‚ùì Now estimate the model, with an early stopping criterion on the validation accuracy - here, the validation data are provided, therefore use `validation_data` instead of `validation_split`.\n",
    "\n",
    "‚ùó **Remark** ‚ùó Store the results in a `history` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34224,
     "status": "ok",
     "timestamp": 1619621359608,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "grmnNmjeAXcQ",
    "outputId": "2dd5b5f9-d018-4c46-84c7-377f824d1b68",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec_I9JpiAm-W"
   },
   "source": [
    "‚ùì **Question** ‚ùì Plot the accuracy for the test and validation set using the usual function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1619621375938,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "HADG7rn8F7TU"
   },
   "outputs": [],
   "source": [
    "def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
    "    if axs is not None:\n",
    "        ax1, ax2 = axs\n",
    "    else:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    if len(exp_name) > 0 and exp_name[0] != '_':\n",
    "        exp_name = '_' + exp_name\n",
    "    ax1.plot(history.history['loss'], label='train' + exp_name)\n",
    "    ax1.plot(history.history['val_loss'], label='val' + exp_name)\n",
    "    #ax1.set_ylim(0., 2.2)\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='train accuracy'  + exp_name)\n",
    "    ax2.plot(history.history['val_accuracy'], label='val accuracy'  + exp_name)\n",
    "    #ax2.set_ylim(0.25, 1.)\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.legend()\n",
    "    return (ax1, ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 1240,
     "status": "ok",
     "timestamp": 1619621376478,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "ESzinGOY6aBc",
    "outputId": "28028c0e-6e9d-43cb-cf72-d8b0925e5c7b",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3plexlQAtcC"
   },
   "source": [
    "‚ùì **Question** ‚ùì Evaluate the model accuracy on the test set. Did we improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1312,
     "status": "ok",
     "timestamp": 1619621462529,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "ps_9HwUyRVj9",
    "outputId": "d6bb097d-07be-4d46-c5a1-fcdeb52efb71",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oF39HIb7BSOy"
   },
   "source": [
    "# (OPTIONAL). Improve the model\n",
    "\n",
    "You can here try to improve the model test accuracy. To do that, here are some options you can consider\n",
    "\n",
    "1. **Unfreeze and finetune**: As per [Google tutorial](https://www.tensorflow.org/guide/keras/transfer_learning#fine-tuning) \n",
    ">_Once your model has converged on the new data, you can try to unfreeze all or part of the base model and retrain the whole model end-to-end with a very low learning rate. This is an optional last step that can potentially give you incremental improvements. It could also potentially lead to quick overfitting -- keep that in mind. It is critical to only do this step after the model with frozen layers has been trained to convergence. If you mix randomly-initialized trainable layers with trainable layers that hold pre-trained features, the randomly-initialized layers will cause very large gradient updates during training, which will destroy your pre-trained features. It's also critical to use a very low learning rate at this stage, because you are training a much larger model than in the first round of training, on a dataset that is typically very small. As a result, you are at risk of overfitting very quickly if you apply large weight updates. Here, you only want to readapt the pretrained weights in an incremental way._\n",
    "\n",
    "\n",
    "1. Add **data augmentation** if your model is overfitting. \n",
    "\n",
    "1. If your model is not - unlikely here - , try a more complex model.\n",
    "\n",
    "1. Perform precise **grid search** on all the hyper-parameters: learning_rate, batch_size, data augmentation etc...\n",
    "\n",
    "1. **Change the base model** to more modern one (resnet, efficient net1. available in the keras library\n",
    "\n",
    "1. Curate the data: maintaining a sane data set is one of the keys to success.\n",
    "\n",
    "1. Obtain more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÅ Congratulation üèÅ \n",
    "Copy this notebook from your google drive into your local data-challenge repo, and commit+push your progress on github. To find where this Colab notebook has been save, click on `File --> Locate in Drive`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}