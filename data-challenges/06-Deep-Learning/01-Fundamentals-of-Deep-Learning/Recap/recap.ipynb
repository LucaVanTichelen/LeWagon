{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECAP\n",
    "- Intro: How to read the doc\n",
    "- Part 1: Tensorflow de-mystified (üë®üèª‚Äçüè´ Teacher's lead)\n",
    "- Part 2: Boston Housing Challenge (üë©‚Äçüéì Students' lead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro: How to read the doc?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ [Tensorflow.org](https://www.tensorflow.org/overview) provides you with two main pages to refer to:\n",
    "- [Tutorial](https://www.tensorflow.org/tutorials)\n",
    "- [Guide](https://www.tensorflow.org/guide)\n",
    "- **These should be your go-to pages**. You can even run `Colab-Notebooks` of these tutorials\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "üëâ TensorFlow [API docs](https://www.tensorflow.org/api_docs/python/tf/) is more austere, and contains advanced notions\n",
    "- It pops up in Google Search in priority\n",
    "- [Sometimes](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential), it can give you references to related Tutorials or Guides\n",
    "- **Use it as single source of truth**\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "üëâ [Keras.io](https://keras.io/about/) is somehow redundant with the TensorFlow documentations\n",
    "- It contains nice tutorials and examples but...\n",
    "- ...use it only you don't find what you need on `Tensorflow.Keras`'s website\n",
    "- **Don't use if for the docs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. Tensorflow demystified \n",
    "üßëüèª‚Äçüè´ Teacher's lead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Goal: Using Tensorflow, create a dummy dataset and fit a dummy model with it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tensors?\n",
    "üìö [Online Guide](https://www.tensorflow.org/guide/tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's OK to import everything for a notebook experimentation!\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors are wrappers around numpy objects\n",
    "\n",
    "X = tf.constant([[1., 1., 1.],\n",
    "                 [1., 1., 1.],\n",
    "                 [1., 1., 1.]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.ones((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X.numpy()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors have a shape\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors can be initialized from Numpy objects\n",
    "tf.constant(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# They can be manipulated with syntax that is similar to Numpy\n",
    "tf.add(X,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversely, Numpy also accept Tensor elements!\n",
    "np.add(X,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a custom MSE loss function using Tensors\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    err = y_true - y_pred\n",
    "    return tf.reduce_mean(tf.square(err))\n",
    "\n",
    "y_true = tf.ones((10,3))\n",
    "y_pred = tf.ones((10,3)) + 0.1 * tf.random.normal((10,3))\n",
    "\n",
    "loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Tensors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sparse Tensors**\n",
    "<img src=\"https://github.com/lewagon/data-images/blob/master/DL/sparse_tensors.png?raw=true\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],\n",
    "                                       values=[1, 2],\n",
    "                                       dense_shape=[3, 4])\n",
    "sparse_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ragged Tensors**\n",
    "<img src=\"https://raw.githubusercontent.com/lewagon/data-images/master/DL/ragged_tensors.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragged_list = [\n",
    "    [0, 1, 2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7, 8],\n",
    "    [9]]\n",
    "\n",
    "ragged_tensor = tf.ragged.constant(ragged_list)\n",
    "ragged_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build a neural network with `Sequential API`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Let's generate 10 random observations `X` of 3 features each, and a unidimensional target `y` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate 100 observations of with 10 features for each of them\n",
    "X = tf.random.uniform((100,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And create our dummy target as simply the mean of each observation\n",
    "y = tf.reduce_mean(X, axis=1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Let's build a simple dense model that \"works\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual syntax\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(30, input_dim=10, activation='relu'))\n",
    "#model.add(layers.Dense(30, input_shape=(10,), activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent\n",
    "model = Sequential([\n",
    "    layers.Dense(30, input_shape=(10, ), activation='relu'),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we don't specify input_dim ?\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(30, activation='relu'))\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.summary()\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One can still access all the layers individually\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And call the layer with a \"tensor\" as input\n",
    "x1 = model.layers[0](X)\n",
    "\n",
    "# x1 is our activation from layer 1, with random (initial) weights\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x2 is our output\n",
    "x2 = model.layers[1](x1)\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Keras Input layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will often encounter this in the docs:\n",
    "```python\n",
    "keras.Input(shape=(10,))\n",
    "```\n",
    "Instead of passing 100 **real** observations to your layers, simply pass a `keras.Input` of `None` observations of similar shape (10,).  \n",
    "\n",
    "It is used for computation optimization purposes (memory pre-allocation and network graphs for parallelization) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(10,))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0](inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.layers[0](inputs) # Input layer\n",
    "x = layers.Dense(30, activation='relu')(inputs) # First layer output\n",
    "x = layers.Dense(20, activation='relu')(x) # Second layer output\n",
    "x = layers.Dense(10, activation='relu')(x) # Third layer output\n",
    "outputs = layers.Dense(1)(x)               # Final layer output\n",
    "\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras allows you to build a model from an input and output layer\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è This way of building models is called Keras [Functional API](https://www.tensorflow.org/guide/keras/functional)\n",
    "- as opposed to [Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential): `model.add(...)`\n",
    "- It is mandatory for complex (non-sequential) architecture...\n",
    "- Used everywhere in the doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Boston Housing Challenge \n",
    "(üë©‚ÄçüéìStudents' lead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "`Tensorflow.Keras` provides `Toy Datasets` that can be found <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/datasets\">here</a>\n",
    "\n",
    "Let's load the **`Boston Housing`** dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = datasets.boston_housing.load_data()\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Normalize your data (by the mean of the train set for instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare the general architecture of your model\n",
    "\n",
    "‚ùì Import Keras and declare a Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Add a Dense layer with 50 neurons and the `relu` activation function. Do not forget to specify your `input_dim` for the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Add a second fully connected layer, with 20 neurons and the `relu` activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Add a last layer that suits your regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Check the number of parameters of your model.\n",
    "\n",
    "Re-count them manually to make sure you understood the numbers of parameters involved for each layer of your Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define how your model is trained\n",
    " \n",
    "‚ùì Compile the model with the `adam` `optimizer` and the `mse` `loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìRun the model on this random data ; don't forget to select a number of `epochs` and a `batch_size`. Store the returned result in `history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Plot the model convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Write an entire model with its compilation within an `init_model` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are advised to systematically rebuild a model (with an init function) before fitting some data in order to re-initialize the model's parameters.\n",
    "\n",
    "The model you just wrote is suited for regression tasks.\n",
    "\n",
    "What if we want to perform a binary classification task ?\n",
    "\n",
    "‚ùì Write another `init_model_2` function in which you will change :\n",
    "* the last layer of the architecture \n",
    "* and the compilation method\n",
    "\n",
    "used in a binary class classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Write a last function to define a model for a classification problem with 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}