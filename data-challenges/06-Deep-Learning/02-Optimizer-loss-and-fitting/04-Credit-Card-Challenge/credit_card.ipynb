{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0060abc6",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87c584e",
   "metadata": {},
   "source": [
    "All the previous exercises made you take a closer look at all the different parts of a neural network: \n",
    "* the architecture of a sequential Dense Neural Network, \n",
    "* the compilation method\n",
    "* the fitting.\n",
    "\n",
    "Let's now work on a real-life dataset that has **a lot of data**!\n",
    "\n",
    "**The dataset : `Credit Card Transactions`**\n",
    "\n",
    "For this open challenge, you will `work with data extracted from credit card transactions`. \n",
    "\n",
    "As these are `sensitive data`, from all the 31 columns, only 3 columns are known: the rest are data that have been transformed to `anonymize` them (in fact, they are `PCA projections of initial data`).\n",
    "\n",
    "The other three known columns are:\n",
    "\n",
    "* `TIME`: the time elapsed between the transaction and the first transaction in the dataset\n",
    "* `AMOUNT`: the amount of the transaction\n",
    "* `CLASS` (our target): \n",
    "    * `0 : valid transaction` \n",
    "    * `1 : fraudulent transaction`\n",
    "\n",
    "‚ùì **Question** ‚ùì Start by downloading the dataset:\n",
    "* on the Kaggle website [here](https://www.kaggle.com/mlg-ulb/creditcardfraud) \n",
    "* or from our [URL](https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/creditcard.csv) \n",
    "\n",
    "Load data to create `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "ddf23eca",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c30cf70",
   "metadata": {},
   "source": [
    "## 1. Rebalancing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "5fe9b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check class balance\n",
    "pd.Series(y).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f1d4a3",
   "metadata": {},
   "source": [
    "‚òùÔ∏è in this `fraud detection` challenge, **the classes are extremely imbalanced**:\n",
    "* 99.8 % of normal transactions\n",
    "* 0.2 % of fraudulent transactions\n",
    "\n",
    "**We won't be able to detect frauds unless we apply some serious rebalancing strategies!**\n",
    "\n",
    "‚ùì **Question** ‚ùì\n",
    "1. **First**, create three separate splits `Train/Val/Test` from your dataset. It is extremely important to keep validation and testing sets **unbalanced** so that when you evaluate your model, it is done in true conditions, without data leakage. Keep your test set for the very last cell of this notebook... !\n",
    "\n",
    "&nbsp;\n",
    "2. **Second**, rebalance you training set (and only this one). You have many choices:\n",
    "\n",
    "- Simply oversample the minority class randomly using plain Numpy functions (not the best option since you are duplicating rows and hence creating data leakage)\n",
    "- Or use <a href=\"https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\">**`Synthetic Minority Oversampling Technique - SMOTE`**</a> to generate new datapoints by weighting the existing ones\n",
    "- In addition, you can also try a <a href=\"https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\">**`RandomUnderSampler`**</a> to downsample the majority class a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "accdcd48",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6575fc40",
   "metadata": {},
   "source": [
    "## 2. Neural Network iterations\n",
    "\n",
    "Now that you have rebalanced your classes, try to fit a neural network to optimize your test score. Feel free to use the following hints:\n",
    "\n",
    "- Normalize your inputs!\n",
    "    - Use preferably a [`Normalization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization) layer inside the model to \"pipeline\" your preprocessing within your model. \n",
    "    - Or use sklearn's [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) outside of your model, applied your `X_train` and `X_val` and `X_test`.\n",
    "- Make your model overfit, then, regularize  it using:\n",
    "    - Early Stopping criteria \n",
    "    - [`Dropout`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) layers\n",
    "    - or [`regularizers`](https://www.tensorflow.org/api_docs/python/tf/keras/regularizers) layers\n",
    "- üö® Think carefully about the metrics you want to track and the loss function you want to use... !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "4e9ac4ff",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f105ed0",
   "metadata": {},
   "source": [
    "### üß™ Test your score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee8987",
   "metadata": {},
   "source": [
    "Store below your real test performance on a (`X_test`, `y_test`) representative sample of the original unbalanced dataset into `precision` and `recall` variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "9256f166",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "dbe064d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('solution',\n",
    "    precision=precision,\n",
    "    recall=recall,\n",
    "    fraud_number=len(y_test[y_test == 1]),\n",
    "    non_fraud_number=len(y_test[y_test == 0]),\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba04b243",
   "metadata": {},
   "source": [
    "## üèÅ Optional : Read Google's solution for this challenge\n",
    "Congratulations for finishing all challenges for this session!\n",
    "\n",
    "To conclude, take some time to read Google's own solution direcly [on Colab here](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb). \n",
    "\n",
    "You will discover interesting techniques and best practices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "716a934b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}