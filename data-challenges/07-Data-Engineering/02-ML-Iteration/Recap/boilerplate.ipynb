{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxifare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_data():\n",
    "    url = \"s3://wagon-public-datasets/taxi-fare-train.csv\"\n",
    "    df = pd.read_csv(url, nrows=100)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-06-15 17:26:21.0000001</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-06-15 17:26:21 UTC</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05 16:52:16.0000002</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2010-01-05 16:52:16 UTC</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-08-18 00:35:00.00000049</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2011-08-18 00:35:00 UTC</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            key  fare_amount          pickup_datetime  \\\n",
       "0   2009-06-15 17:26:21.0000001          4.5  2009-06-15 17:26:21 UTC   \n",
       "1   2010-01-05 16:52:16.0000002         16.9  2010-01-05 16:52:16 UTC   \n",
       "2  2011-08-18 00:35:00.00000049          5.7  2011-08-18 00:35:00 UTC   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.844311        40.721319         -73.841610         40.712278   \n",
       "1        -74.016048        40.711303         -73.979268         40.782004   \n",
       "2        -73.982738        40.761270         -73.991242         40.750562   \n",
       "\n",
       "   passenger_count  \n",
       "0                1  \n",
       "1                1  \n",
       "2                2  "
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    df = df.dropna(how='any', axis='rows')\n",
    "    df = df[(df.dropoff_latitude != 0) | (df.dropoff_longitude != 0)]\n",
    "    df = df[(df.pickup_latitude != 0) | (df.pickup_longitude != 0)]\n",
    "    if \"fare_amount\" in list(df):\n",
    "        df = df[df.fare_amount.between(0, 4000)]\n",
    "    df = df[df.passenger_count < 8]\n",
    "    df = df[df.passenger_count >= 1]\n",
    "    df = df[df[\"pickup_latitude\"].between(left=40, right=42)]\n",
    "    df = df[df[\"pickup_longitude\"].between(left=-74.3, right=-72.9)]\n",
    "    df = df[df[\"dropoff_latitude\"].between(left=40, right=42)]\n",
    "    df = df[df[\"dropoff_longitude\"].between(left=-74, right=-72.9)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8)"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 8)"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_train = df[\"fare_amount\"]\n",
    "X_train = df.drop(\"fare_amount\", axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=1)"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_params = dict(\n",
    "  n_estimators=100,\n",
    "  max_depth=1)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.set_params(**model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski_distance(df, p,\n",
    "                       start_lat=\"pickup_latitude\",\n",
    "                       start_lon=\"pickup_longitude\",\n",
    "                       end_lat=\"dropoff_latitude\",\n",
    "                       end_lon=\"dropoff_longitude\"):\n",
    "    x1 = df[start_lon]\n",
    "    x2 = df[end_lon]\n",
    "    y1 = df[start_lat]\n",
    "    y2 = df[end_lat]\n",
    "    return ((abs(x2 - x1) ** p) + (abs(y2 - y1)) ** p) ** (1 / p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DistanceTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, distance_type=\"euclidian\", **kwargs):\n",
    "        self.distance_type = distance_type\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        if self.distance_type == \"euclidian\":\n",
    "            X[\"distance\"] = minkowski_distance(X, p=2)\n",
    "        if self.distance_type == \"manhattan\":\n",
    "            X[\"distance\"] = minkowski_distance(X, p=1)\n",
    "        return X[[\"distance\"]]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "pipe_distance = make_pipeline(\n",
    "    DistanceTransformer(),\n",
    "    StandardScaler())\n",
    "\n",
    "\n",
    "cols = [\"pickup_latitude\", \"pickup_longitude\", \"dropoff_latitude\", \"dropoff_longitude\"]\n",
    "\n",
    "feateng_blocks = [\n",
    "    ('distance', pipe_distance, cols),\n",
    "]\n",
    "\n",
    "features_encoder = ColumnTransformer(feateng_blocks)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "            ('features', features_encoder),\n",
    "            ('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 ColumnTransformer(transformers=[('distance',\n",
       "                                                  Pipeline(steps=[('distancetransformer',\n",
       "                                                                   DistanceTransformer()),\n",
       "                                                                  ('standardscaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['pickup_latitude',\n",
       "                                                   'pickup_longitude',\n",
       "                                                   'dropoff_latitude',\n",
       "                                                   'dropoff_longitude'])])),\n",
       "                ('model', RandomForestRegressor(max_depth=1))])"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_rmse(y_pred, y_true):\n",
    "    return np.sqrt(((y_pred - y_true) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = compute_rmse(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.589335478037243"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memoized_property import memoized_property\n",
    "\n",
    "import mlflow\n",
    "from  mlflow.tracking import MlflowClient\n",
    "\n",
    "class MLFlowBase():\n",
    "\n",
    "    def __init__(self, experiment_name, MLFLOW_URI):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.MLFLOW_URI = MLFLOW_URI\n",
    "\n",
    "    @memoized_property\n",
    "    def mlflow_client(self):\n",
    "        mlflow.set_tracking_uri(self.MLFLOW_URI)\n",
    "        return MlflowClient()\n",
    "\n",
    "    @memoized_property\n",
    "    def mlflow_experiment_id(self):\n",
    "        try:\n",
    "            return self.mlflow_client \\\n",
    "                .create_experiment(self.experiment_name)\n",
    "        except BaseException:\n",
    "            return self.mlflow_client \\\n",
    "                .get_experiment_by_name(self.experiment_name).experiment_id\n",
    "\n",
    "    def mlflow_create_run(self):\n",
    "        self.mlflow_run = self.mlflow_client \\\n",
    "            .create_run(self.mlflow_experiment_id)\n",
    "\n",
    "    def mlflow_log_param(self, key, value):\n",
    "        self.mlflow_client \\\n",
    "            .log_param(self.mlflow_run.info.run_id, key, value)\n",
    "\n",
    "    def mlflow_log_metric(self, key, value):\n",
    "        self.mlflow_client \\\n",
    "            .log_metric(self.mlflow_run.info.run_id, key, value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gmanchon/.pyenv/versions/3.8.5/envs/data_502/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('features',\n",
       "   ColumnTransformer(transformers=[('distance',\n",
       "                                    Pipeline(steps=[('distancetransformer',\n",
       "                                                     DistanceTransformer()),\n",
       "                                                    ('standardscaler',\n",
       "                                                     StandardScaler())]),\n",
       "                                    ['pickup_latitude', 'pickup_longitude',\n",
       "                                     'dropoff_latitude', 'dropoff_longitude'])])),\n",
       "  ('model', RandomForestRegressor(max_depth=1))],\n",
       " 'verbose': False,\n",
       " 'features': ColumnTransformer(transformers=[('distance',\n",
       "                                  Pipeline(steps=[('distancetransformer',\n",
       "                                                   DistanceTransformer()),\n",
       "                                                  ('standardscaler',\n",
       "                                                   StandardScaler())]),\n",
       "                                  ['pickup_latitude', 'pickup_longitude',\n",
       "                                   'dropoff_latitude', 'dropoff_longitude'])]),\n",
       " 'model': RandomForestRegressor(max_depth=1),\n",
       " 'features__n_jobs': None,\n",
       " 'features__remainder': 'drop',\n",
       " 'features__sparse_threshold': 0.3,\n",
       " 'features__transformer_weights': None,\n",
       " 'features__transformers': [('distance',\n",
       "   Pipeline(steps=[('distancetransformer', DistanceTransformer()),\n",
       "                   ('standardscaler', StandardScaler())]),\n",
       "   ['pickup_latitude',\n",
       "    'pickup_longitude',\n",
       "    'dropoff_latitude',\n",
       "    'dropoff_longitude'])],\n",
       " 'features__verbose': False,\n",
       " 'features__distance': Pipeline(steps=[('distancetransformer', DistanceTransformer()),\n",
       "                 ('standardscaler', StandardScaler())]),\n",
       " 'features__distance__memory': None,\n",
       " 'features__distance__steps': [('distancetransformer', DistanceTransformer()),\n",
       "  ('standardscaler', StandardScaler())],\n",
       " 'features__distance__verbose': False,\n",
       " 'features__distance__distancetransformer': DistanceTransformer(),\n",
       " 'features__distance__standardscaler': StandardScaler(),\n",
       " 'features__distance__distancetransformer__distance_type': 'euclidian',\n",
       " 'features__distance__standardscaler__copy': True,\n",
       " 'features__distance__standardscaler__with_mean': True,\n",
       " 'features__distance__standardscaler__with_std': True,\n",
       " 'model__bootstrap': True,\n",
       " 'model__ccp_alpha': 0.0,\n",
       " 'model__criterion': 'mse',\n",
       " 'model__max_depth': 1,\n",
       " 'model__max_features': 'auto',\n",
       " 'model__max_leaf_nodes': None,\n",
       " 'model__max_samples': None,\n",
       " 'model__min_impurity_decrease': 0.0,\n",
       " 'model__min_impurity_split': None,\n",
       " 'model__min_samples_leaf': 1,\n",
       " 'model__min_samples_split': 2,\n",
       " 'model__min_weight_fraction_leaf': 0.0,\n",
       " 'model__n_estimators': 100,\n",
       " 'model__n_jobs': None,\n",
       " 'model__oob_score': False,\n",
       " 'model__random_state': None,\n",
       " 'model__verbose': 0,\n",
       " 'model__warm_start': False}"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gmanchon/.pyenv/versions/3.8.5/envs/data_502/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'features__distance__standardscaler__copy': True,\n",
       " 'model__min_samples_leaf': 3,\n",
       " 'model__min_weight_fraction_leaf': 0.0,\n",
       " 'model__oob_score': True}"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, \n",
    "    param_grid={\n",
    "        'features__distance__standardscaler__copy': [True],\n",
    "        'model__min_samples_leaf': [3],\n",
    "        'model__oob_score': [True],\n",
    "        'model__min_weight_fraction_leaf': [0.0, 0.1]\n",
    "    },\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.score(X_test, y_test)\n",
    "\n",
    "grid_search.best_estimator_\n",
    "grid_search.best_params_"
   ]
  }
 ],
 "metadata": {
  "challengify": {
   "keep_output": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
